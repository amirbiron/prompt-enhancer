"""
Refiner Agent
住 砖砖驻专 驻专驻 注 住住 拽专转
"""
import json
import logging
from typing import Optional, List
import google.generativeai as genai

from config import config
from core.models import PromptCategory, CritiqueResult, Weakness, MissingParameter, ProTip

logger = logging.getLogger(__name__)


class PromptRefiner:
    """
    住 砖砖驻专 驻专驻 注 住住:
    - 拽转 砖 砖
    - 驻专专 住专
    - best practices 拽专
    
    砖转砖  转 转专 (Gemini Pro)   砖 拽专.
    """
    
    def __init__(self):
        genai.configure(api_key=config.GEMINI_API_KEY)
        #  转 转专 砖驻专
        self.model = genai.GenerativeModel('gemini-2.0-flash')
    
    async def refine(
        self,
        original_prompt: str,
        category: PromptCategory,
        critique: CritiqueResult,
        user_answers: Optional[dict] = None
    ) -> str:
        """
        砖驻专 驻专驻 注 住住 拽专转 驻 拽爪注.
        
        Args:
            original_prompt: 驻专驻 拽专
            category: 拽专 砖转
            critique: 转爪转 拽专转
            user_answers: 转砖转 砖转砖 砖转 (驻爪)
            
        Returns:
            驻专驻 砖驻专
        """
        # 转 拽砖专 拽专转
        weaknesses_text = self._format_weaknesses(critique.weaknesses)
        missing_params_text = self._format_missing_params(critique.missing_params)
        pro_tips_text = self._format_pro_tips(critique.pro_tips)
        user_answers_text = self._format_user_answers(user_answers) if user_answers else ""
        
        refinement_prompt = f"""[爪 砖驻专 驻专驻 拽爪注 - 注专转]

驻专驻 拽专:
"{original_prompt}"

拽专: {category.value}
爪 : {critique.overall_score}/10

## 拽转 砖 转拽:
{weaknesses_text}

## 驻专专 住专:
{missing_params_text}

## 驻 拽爪注 砖 (砖 !):
{pro_tips_text}

{user_answers_text}

## 砖: 爪专 驻专驻 砖驻专 拽爪注

驻专驻 砖驻专 :

1. **转拽 转  拽转 砖** -  注 砖转 爪专 转 驻转
2. **砖 转 驻 拽爪注** -  拽  砖! 转砖转砖 拽转 砖爪
3. **砖专 注  拽专转** -  转砖 转 专 砖 砖转砖
4. **转 拽爪注 驻拽** - 驻专驻 砖转 转爪转 转 转专

拽转 砖 砖拽:
-  Role Playing: 专  转驻拽   专
-  Chain of Thought: 拽砖 砖 砖  砖 专转
-  Few-Shot: 住祝  驻 专爪   专专
-  Constraints: 住祝 转 砖转 转 砖
-  Structure: 专 转 驻专驻  专专

专 专拽 转 驻专驻 砖驻专,  住专  注专转 住驻转.
驻专驻 爪专 转  砖砖 砖专."""

        try:
            response = await self.model.generate_content_async(
                refinement_prompt,
                generation_config={
                    "temperature": 0.4,  #  -  爪专转 ,  拽砖 
                    "max_output_tokens": 1000
                }
            )
            
            improved = response.text.strip()
            
            # 拽 住 拽  砖
            improved = improved.strip('`').strip()
            if improved.startswith('text\n'):
                improved = improved[5:]
            
            return improved
            
        except Exception as e:
            logger.error(f"Refinement failed: {e}")
            raise
    
    async def refine_iterative(
        self,
        original_prompt: str,
        category: PromptCategory,
        max_iterations: int = 3,
        target_score: int = 8
    ) -> tuple[str, int, List[CritiqueResult]]:
        """
        砖驻专 专 - 砖 砖驻专 注 砖注 爪 注.
        
        Args:
            original_prompt: 驻专驻 拽专
            category: 拽专
            max_iterations: 拽住 专爪转
            target_score: 爪 注 (注爪专 砖注)
            
        Returns:
            tuple 砖 (驻专驻 砖驻专, 住驻专 专爪转, 住专转 拽专转)
        """
        from agents.shadow_critic import ShadowCritic
        critic = ShadowCritic()
        
        current_prompt = original_prompt
        critiques_history = []
        
        for iteration in range(max_iterations):
            logger.info(f"Iteration {iteration + 1}/{max_iterations}")
            
            # 拽专转
            critique = await critic.critique(current_prompt, category)
            critiques_history.append(critique)
            
            logger.info(f"Score: {critique.overall_score}/10")
            
            # 拽  注 注
            if critique.overall_score >= target_score or critique.is_ready:
                logger.info(f"Target reached at iteration {iteration + 1}")
                return current_prompt, iteration + 1, critiques_history
            
            # 砖驻专
            current_prompt = await self.refine(
                original_prompt=current_prompt,
                category=category,
                critique=critique
            )
        
        return current_prompt, max_iterations, critiques_history
    
    def _format_weaknesses(self, weaknesses: List[Weakness]) -> str:
        """注爪 拽转 砖 拽住"""
        if not weaknesses:
            return "  拽转 砖 砖注转转"
        
        lines = []
        for i, w in enumerate(weaknesses, 1):
            lines.append(f"{i}. [{w.type}] {w.description}")
            lines.append(f"   爪注: {w.suggestion}")
        return "\n".join(lines)
    
    def _format_missing_params(self, params: List[MissingParameter]) -> str:
        """注爪 驻专专 住专 拽住"""
        if not params:
            return "  驻专专 住专 拽专"
        
        lines = []
        for p in params:
            importance = "" if p.importance == "required" else "抓"
            lines.append(f"- {p.name} ({importance}): {p.question}")
        return "\n".join(lines)
    
    def _format_pro_tips(self, tips: List[ProTip]) -> str:
        """注爪 驻 拽爪注 拽住"""
        if not tips:
            return "  驻 住驻爪驻"
        
        technique_names = {
            "role_playing": "专转 转驻拽",
            "chain_of_thought": "砖 砖-专-砖",
            "few_shot": "转",
            "constraints": "转",
            "structure": "",
            "creativity": "爪专转转"
        }
        
        lines = []
        for i, tip in enumerate(tips, 1):
            technique = technique_names.get(tip.technique, tip.technique)
            lines.append(f"{i}. [{technique}] {tip.title}")
            lines.append(f"   爪注: {tip.suggestion}")
            if tip.example:
                lines.append(f"   : \"{tip.example}\"")
        return "\n".join(lines)
    
    def _format_user_answers(self, answers: dict) -> str:
        """注爪 转砖转 砖转砖"""
        if not answers:
            return ""
        
        lines = ["转砖转 砖转砖:"]
        for key, value in answers.items():
            lines.append(f"- {key}: {value}")
        return "\n".join(lines)
    
    async def generate_explanation(
        self,
        original_prompt: str,
        improved_prompt: str,
        weaknesses: List[Weakness]
    ) -> str:
        """
        爪专 住专 注专转 注 砖驻专 砖注砖.
        """
        explanation_prompt = f"""[住专 砖驻专 - 注专转]

驻专驻 拽专:
"{original_prompt}"

驻专驻 砖驻专:
"{improved_prompt}"

拽转 砖 砖驻:
{self._format_weaknesses(weaknesses)}

转 住专 拽爪专 (3-5 砖驻) 注专转 砖住专:
1.   注转 注拽专转
2.  驻专驻 砖驻专 驻 
3.   砖驻专 转 转爪转

砖专 注  转 注.  转 拽专转 ."""

        try:
            response = await self.model.generate_content_async(
                explanation_prompt,
                generation_config={
                    "temperature": 0.5,
                    "max_output_tokens": 300
                }
            )
            return response.text.strip()
        except Exception as e:
            logger.error(f"Explanation generation failed: {e}")
            return "驻专驻 砖驻专 注  住驻转 驻专 住专 专转 专."
